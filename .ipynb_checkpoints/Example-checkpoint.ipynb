{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import time\n",
    "from functions import plots\n",
    "from functions import finite_volumes as fv\n",
    "from functions import finite_volumes_split as fvs\n",
    "from functions import finite_volumes_par as fvp\n",
    "from functions import neural_network as nn\n",
    "import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE INPAINTING WITH FLUID DYNAMICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image inpainting aims to remove damage from an image. There are various techniques for image inpainting, and here we focus on solving a fluid-type PDE denoted as the Cahn-Hilliard equation.\n",
    "\n",
    "The three take-home messages from this notebook are that:\n",
    "\n",
    "1. Image inpainting can be solved with efficient and parallelizable finite-volume schemes\n",
    "2. The classification accuracy of neural networks is affected by the presence of damage \n",
    "3. The application of image inpainting in damaged images improves their classification accuracy\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "#### Damaged image:\n",
    "<img src=\"images/damage_23.png\" style=\"width:300px;height:250px;\" >\n",
    "\n",
    "#### Restored image:\n",
    "<img src=\"images/inpainting_23.png\" style=\"width:300px;height:250px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we take the MNIST dataset, which consists of binary images of handwritten digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = mnist.test_images() # Load MNIST test set\n",
    "test_images = test_images.reshape((-1,784)) # Flatten\n",
    "test_images = (test_images / 255) *2-1 # Normalize between -1 and 1\n",
    "example = test_images[0,:] # Select 1 image\n",
    "plots.plot_image(example) # Plot image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is corrupted by adding different types of damage to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = 0.5 # elect % of damaged pixels\n",
    "\n",
    "damage = np.random.choice(np.arange(example.size), replace=False, \n",
    "                          size=int(example.size * intensity)) # Create random damage\n",
    "damaged_example = example.copy() # Generate damaged example\n",
    "damaged_example[damage] = 0 # Turn damaged pixels to 0\n",
    "plots.plot_image(damaged_example) # Plot image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite volumes for image inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With image inpainting we aim to recover the original image. There are various methods to conduct image inpainting, and here I solve a modified Cahn-Hilliard equation via finite-volume schemes:\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi (x,t)}{\\partial t}= -\\nabla^{2} \\left(\\epsilon^2 \\nabla^{2} \\phi -  H'(\\phi) \\right) + \\lambda(x)\\left(\\phi (x,t=0) - \\phi\\right)\n",
    "$$\n",
    "\n",
    "As a baseline let's solve this equation with a simple finite-volume scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # Start time\n",
    "restored_example = fv.temporal_loop(damaged_example, damage) # Run finite-volume scheme\n",
    "print(\"Total time: {:.2f}\".format(time.time()-start)) # Print spent time\n",
    "plots.plot_image(restored_example) # Plot image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the restored image with respect to the original image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_3images(example, damaged_example, restored_example)  # Plot 3 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational cost of finite-volume scheme can be reduced by:\n",
    "\n",
    "1. Applying a dimensional-splitting technique and solving row by row and column by column\n",
    "2. Parallelizing the code and solving rows/columns simultaneously\n",
    "\n",
    "The simple finite-volume scheme has taken 40s to run. Let's compare it with the dimensional-splitting code:fully parallelized code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # Start time\n",
    "restored_example = fvs.temporal_loop_split(damaged_example, damage) # Run finite-volume scheme\n",
    "print(\"Total time: {:.2f}\".format(time.time()-start)) # Print spent time\n",
    "plots.plot_image(restored_example) # Plot image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By dimensionally splitting the code we have reduced the computational time from 40s to 8s!\n",
    "\n",
    "Can we reduce that time by parallelizing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_proc = 8 # Number of processors\n",
    "start = time.time() # Start time\n",
    "restored_example = fvp.temporal_loop_par(damaged_example, damage, num_proc) # Run finite-volume scheme\n",
    "print(\"Total time: {:.2f}\".format(time.time()-start)) # Print spent time\n",
    "plots.plot_image(restored_example) # Plot image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallel code takes 15 seconds, which is a higher than the non-parallel one. Parallelizing the code does not reduce that time since MNIST images are only 28x28. However, for high-dimensional images it has a clear benefit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network is trained with the undamaged training dataset. Then we compare its accuracy for the test images with and without damage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images() # Load training set\n",
    "train_labels = mnist.train_labels() # Load training labels\n",
    "train_images = (train_images / 255) *2-1 # Normalize between -1 and 1\n",
    "train_images = train_images.reshape((-1,784)) # Flatten\n",
    "\n",
    "model, history = nn.training(train_images, train_labels) # Train the neural network\n",
    "plots.loss_acc_plots(history) # Plot loss and accuracy\n",
    "\n",
    "test_labels = mnist.test_labels() # Load test labels\n",
    "print(\"Validation of undamaged test set:\")\n",
    "test_loss, test_accuracy = model.evaluate(test_images, to_categorical(test_labels), \n",
    "                                          verbose=2) # Print test loss and acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the test dataset is quite high: 97%. This accuracy drops as we include damage in the test images. For instance, with an intensity of 80% the accuracy is 55%. Can we recover the accuracy by firstly applying image inpainting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image inpainting prior to classifying damaged images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a group of 5 images to add damage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5 # Number of images\n",
    "indices_images = range(5) # Select indices\n",
    "examples = test_images[indices_images,:].copy() # Choose examples from test set\n",
    "\n",
    "intensity = 0.8 # Damage intensity\n",
    "# damages = np.zeros((len(indices_images), int(examples.shape[1] * intensity)), dtype=int) # Instantiate damage matrices\n",
    "# damaged_examples = examples.copy() # Instantiate damaged examples\n",
    "\n",
    "damages = np.load(\"data/damages.npy\") # Load a previously saved damage matrix\n",
    "\n",
    "for i in range(len(indices_images)): # Loop over examples t introduce damage\n",
    "#     damages[i, :] = np.random.choice(np.arange(examples.shape[1]), replace=False, \n",
    "#                                      size=int(examples.shape[1] * intensity)) # Choose random damage\n",
    "    damaged_examples[i, damages[i, :]] = 0 # Turn damaged pixels to 0\n",
    "\n",
    "plots.plot_image(damaged_examples[1,:]) # Plot one of the damaged examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to restore those 5 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_examples = np.zeros(examples.shape) # Instantiate restored examples\n",
    "\n",
    "for i in range(n_images): # Loop over damaged imaged\n",
    "    restored_examples[i,:] = fvs.temporal_loop_split(\n",
    "                                damaged_examples[i, :], damages[i, :])\n",
    "\n",
    "plots.plot_3images(examples[1,:], damaged_examples[1,:], restored_examples[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the ground truth with the predicted labels for the damaged and restore images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_damaged = np.argmax(model.predict(damaged_examples), axis=1)  \n",
    "predictions_restored = np.argmax(model.predict(restored_examples), axis=1)    \n",
    "\n",
    "print(\"Ground truth: \", test_labels[indices_images])\n",
    "print(\"Damaged images: \", predictions_damaged)\n",
    "print(\"Restored images: \", predictions_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three take-home messages from this notebook are that:\n",
    "\n",
    "1. Image inpainting can be solved with efficient and parallelizable finite-volume schemes\n",
    "2. The classification accuracy of neural networks is affected by the presence of damage \n",
    "3. The application of image inpainting in damaged images improves their classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
